{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cryptikmind/Whisper-FT/blob/main/WhisperYouTube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're looking at this on GitHub and new to Python Notebooks or Colab, click the Google Colab badge above üëÜ\n",
        "\n",
        "\n",
        "#**Creating YouTube transcripts with OpenAI's Whisper model** \n",
        "\n",
        "üì∫ Getting started video: https://youtu.be/kENRf82_RQs\n",
        "\n",
        "*Colab beginner notes:*\n",
        "<br>\n",
        "1. These files are being loaded on a virtual machine in the cloud. Nothing is being downloaded to your computer (except for the transcript when you click to download it.) When you close this session the instance will be erased.\n",
        "<br>\n",
        "2. The run button is visible when you move your mouse close to the left edge of the code block. It looks kind of like this: ‚ñ∂Ô∏è ...but round...and white on black...so nothing like this. You'll know it when you see it.\n",
        "\n",
        "###**Note: For faster performance set your runtime to \"GPU\"**\n",
        "*Click on \"Runtime\" in the menu and click \"Change runtime type\". Select \"GPU\".*\n",
        "\n",
        "\n",
        "**Step 1.** Follow the instructions in each block and select the options you want\n",
        "<br> \n",
        "**Step 2.** Get the url of the video you want to transcribe\n",
        "<br> \n",
        "**Step 3.** Refresh the folder on the left and download your transcript\n",
        "<br> \n",
        "**Step 4.** Go to your YouTube account and upload the transcript to the video it came from and use \"autosync.\"\n",
        "\n",
        "That's it!\n",
        "\n",
        "Have a question? Hit me up on Twitter:[ @AndrewMayne](https://twitter.com/andrewmayne)\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**What is this?**\n",
        "<br>\n",
        "This is a Python notebook that creates a transcript from a YouTube url using OpenAI's Whisper transcription model that you can then upload to YouTube using the autosync feature to create captions.\n",
        "<br>  \n",
        "**What is OpenAI's Whisper model?**\n",
        "<br>\n",
        "Whisper is an automatic speech recognition (ASR) neural net created by OpenAI that transcribes audio at close to human level.\n",
        "<br>\n",
        "<br>\n",
        "**Why use this?**\n",
        "<br> \n",
        "The quality of the OpenAI Whisper model is amazing (I am slightly biased, but seriously, check it out.) You can also use it to transcribe in other languages.\n",
        "<br> \n",
        "<br>\n",
        "**What do the different model sizes do?**\n",
        "<br>\n",
        "Each model size has an improvement in quality ‚Äì especially with different languages. I've found that for a YouTube video with clear speech, the base model works really well. If you see transcription errors, you can try a larger model.\n",
        "<br>\n",
        "<br> \n",
        "**Do I need timestamps?**\n",
        "<br> \n",
        "Nope. YouTube's autosync function will match the text to the spoken words and syncs up really well. All you need is each spoken sentence in a .txt file.\n",
        "<br> \n",
        "<br> \n",
        "**How do I do this?**\n",
        "<br> \n",
        "Just follow each step. If you've never used Colab of a Python notebook, don't panic. It's super easy and runs in the cloud.\n",
        "<br> \n",
        "<br> \n",
        "**Does this cost anything to use?**\n",
        "<br>\n",
        "Nope. You can use Colab for free and Whisper is an open source model. \n",
        "<br> \n",
        "<br> \n",
        "[Tips for creating a YouTube transcript file](https://support.google.com/youtube/answer/2734799?hl=en)\n",
        "<br> \n",
        "[Information on OpenAI's Whisper model](https://openai.com/blog/whisper/)\n",
        "<br> \n",
        "[OpenAI's Whisper GitHub page](https://github.com/openai/whisper)\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qvz5JoKjwKAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. Click the start button in the upper left side of this block to load the necessary libraries\n",
        "\n",
        "You will need to run this every time you reload this notebook.\n",
        "\"\"\"\n",
        "\n",
        "!pip install yt-dlp\n",
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install librosa\n",
        "\n",
        "import whisper\n",
        "import time\n",
        "import librosa\n",
        "import re\n",
        "import yt_dlp"
      ],
      "metadata": {
        "id": "j6svgIwL1a-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ea5debf-0685-48f9-87d3-10d0830071fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2022.11.11-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.8 MB 4.5 MB/s \n",
            "\u001b[?25hCollecting websockets\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 106 kB 60.1 MB/s \n",
            "\u001b[?25hCollecting pycryptodomex\n",
            "  Downloading pycryptodomex-3.16.0-cp35-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.3 MB 40.6 MB/s \n",
            "\u001b[?25hCollecting mutagen\n",
            "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 193 kB 62.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from yt-dlp) (2022.9.24)\n",
            "Collecting brotli\n",
            "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 357 kB 67.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: websockets, pycryptodomex, mutagen, brotli, yt-dlp\n",
            "Successfully installed brotli-1.0.9 mutagen-1.46.0 pycryptodomex-3.16.0 websockets-10.4 yt-dlp-2022.11.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-q4vqpc5d\n",
            "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-q4vqpc5d\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.13.0+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (9.0.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.8 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.6 MB 57.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 182 kB 73.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers>=4.19.0->whisper==1.0) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.24.3)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175324 sha256=5dfc10d423476b9b5a9aee6b349110eae958c8788260cc5c4bc9fd145338e187\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lrrpzf8v/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
            "Successfully built whisper\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, ffmpeg-python, whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1 whisper-1.0\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,342 kB]\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,352 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,524 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [1,073 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,567 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,095 kB]\n",
            "Fetched 13.2 MB in 2s (5,791 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "34 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.11.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (4.13.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.11.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "2. Select the model you want to use. \n",
        "\n",
        "Base works really well so it's the default. \n",
        "\n",
        "(For multilingual, remove \".en\" from the model name.)\n",
        "\n",
        "Click the run button after you've made your choice (or left it at default.)\n",
        "\"\"\"\n",
        "\n",
        "# model = whisper.load_model(\"tiny.en\")\n",
        "model = whisper.load_model(\"base.en\")\n",
        "# model = whisper.load_model(\"small.en\")\n",
        "# model = whisper.load_model(\"medium.en\")\n",
        "# model = whisper.load_model(\"large\")"
      ],
      "metadata": {
        "id": "9oRA4UIe104O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "3. Click the run button and input your YouTube URL in the box below then click enter.\n",
        "\n",
        "You can use this one to test: https://www.youtube.com/watch?v=CnT-Na1IeVI\n",
        "\n",
        "The video will be loaded and the audio extracted (this is usually the longest part of the process.)\n",
        "\n",
        "Your transcript will appear in the folder on the left (you may have to refresh the folder to see it.)\n",
        "\n",
        "You can download the file when it's completed and upload it on your video's detail page using \"autosync.\"\n",
        "\"\"\"\n",
        "\n",
        "# This will prompt you for a YouTube video URL\n",
        "url = input(\"Enter a YouTube video URL: \")\n",
        "\n",
        "# Create a youtube-dl options dictionary\n",
        "ydl_opts = {\n",
        "    # Specify the format as bestaudio/best\n",
        "    'format': 'bestaudio/best',\n",
        "    # Specify the post-processor as ffmpeg to extract audio and convert to mp3\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'mp3',\n",
        "        'preferredquality': '192',\n",
        "    }],\n",
        "    # Specify the output filename as the video title\n",
        "    'outtmpl': '%(title)s.%(ext)s',\n",
        "}\n",
        "\n",
        "# Download the video and extract the audio\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([url])\n",
        "\n",
        "# Get the path of the file\n",
        "file_path = ydl.prepare_filename(ydl.extract_info(url, download=False))\n",
        "file_path = file_path.replace('.webm', '.mp3')\n",
        "file_path = file_path.replace('.m4a', '.mp3')\n",
        "\n",
        "# Get the duration\n",
        "duration = librosa.get_duration(filename=file_path)\n",
        "start = time.time()\n",
        "options = dict(without_timestamps=False)\n",
        "result = model.transcribe(file_path)\n",
        "end = time.time()\n",
        "seconds = end - start\n",
        "\n",
        "#print(\"Raw: \", result)\n",
        "print(\"Video length:\", duration, \"seconds\")\n",
        "print(\"Transcription time:\", seconds)\n",
        "\n",
        "# Save the file as .txt\n",
        "name = \"\".join(file_path) + \".txt\"\n",
        "with open(name, \"w\") as f:\n",
        "  for s in result[\"segments\"]:\n",
        "    iOut = \"@\" + f'{s[\"start\"]:.2f}' + \"\\n\" + s[\"text\"].strip() + \"\\n\"\n",
        "    print(iOut)\n",
        "    #f.write(iOut)\n",
        "\n",
        "\"\"\"\n",
        "# vvv This block is the alternative to the 'Save the file as .txt' above and will just output the text. \n",
        "#     But in this case the text will be grouped by sentence (instead of segment as it is above)\n",
        "# Split result[\"text\"]  on !,? and . , but save the punctuation\n",
        "sentences = re.split(\"([!?.])\", result[\"text\"])\n",
        "\n",
        "# Join the punctuation back to the sentences\n",
        "sentences = [\"\".join(i) for i in zip(sentences[0::2], sentences[1::2])]\n",
        "text = \"\\n\\n\".join(sentences)\n",
        "for s in sentences:\n",
        "  print(s)\n",
        "\n",
        "# Save the file as .txt\n",
        "name = \"\".join(file_path) + \".txt\"\n",
        "with open(name, \"w\") as f:\n",
        "  f.write(text)\n",
        "\n",
        "print(\"\\n\\n\", \"-\"*100, \"\\n\\nYour transcript is here:\", name)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JmbHC2-S33Kl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}